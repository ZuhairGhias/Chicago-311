
======================================================================
CHICAGO 311 SERVICE REQUEST RESPONSE TIME PREDICTION
======================================================================

Loading data...
Capped at P99 (147.8 days): removed 22,000 outliers (1.0%)

Temporal Split Summary:
  Train: 1,306,776 samples (2020-01-01 to 2023-05-27)
  Val:   435,592 samples (2023-05-27 to 2024-07-20)
  Test:  435,592 samples (2024-07-20 to 2025-09-30)
  Total: 2,177,960 samples

======================================================================
RUNNING BASELINE METHODS
======================================================================
Baseline_0_Global         MAE: 14.1621, RMSE: 20.2196
Baseline_1_SR_TYPE        MAE: 12.0369, RMSE: 20.3727
Baseline_2_ZIP            MAE: 14.1842, RMSE: 20.2262
Baseline_3_SR_ZIP         MAE: 13.4766, RMSE: 21.1897

======================================================================
RUNNING XGBOOST (Time-Series CV)
======================================================================
Running 5-fold time-series CV...
  Fold 1: best_iteration = 395
  Fold 2: best_iteration = 428
  Fold 3: best_iteration = 173
  Fold 4: best_iteration = 798
  Fold 5: best_iteration = 96
  Average best iterations: 378
XGB_Conservative          MAE: 9.9689, RMSE: 20.1048

======================================================================
RUNNING RANDOM FOREST
======================================================================
RF_Conservative           MAE: 9.7249, RMSE: 19.8887

======================================================================
RUNNING LIGHTGBM ENSEMBLE (Time-Series CV)
======================================================================
Running 5-fold time-series CV to find optimal iterations...
Training until validation scores don't improve for 50 rounds
[50]	train's l1: 0.498529	valid's l1: 0.620403
[100]	train's l1: 0.421794	valid's l1: 0.526525
[150]	train's l1: 0.409107	valid's l1: 0.513606
[200]	train's l1: 0.405685	valid's l1: 0.512537
Early stopping, best iteration is:
[191]	train's l1: 0.406038	valid's l1: 0.512351
  Fold 1: best_iteration = 191
Training until validation scores don't improve for 50 rounds
[50]	train's l1: 0.50315	valid's l1: 0.750005
[100]	train's l1: 0.413556	valid's l1: 0.691016
[150]	train's l1: 0.397346	valid's l1: 0.683137
[200]	train's l1: 0.392108	valid's l1: 0.684726
Early stopping, best iteration is:
[163]	train's l1: 0.395226	valid's l1: 0.682701
  Fold 2: best_iteration = 163
Training until validation scores don't improve for 50 rounds
[50]	train's l1: 0.558363	valid's l1: 0.697899
[100]	train's l1: 0.479218	valid's l1: 0.664125
Early stopping, best iteration is:
[93]	train's l1: 0.483557	valid's l1: 0.663265
  Fold 3: best_iteration = 93
Training until validation scores don't improve for 50 rounds
[50]	train's l1: 0.588627	valid's l1: 0.732687
[100]	train's l1: 0.513559	valid's l1: 0.692545
[150]	train's l1: 0.50112	valid's l1: 0.687574
[200]	train's l1: 0.498285	valid's l1: 0.686496
[250]	train's l1: 0.497821	valid's l1: 0.686229
[300]	train's l1: 0.497716	valid's l1: 0.686104
[350]	train's l1: 0.496975	valid's l1: 0.686149
[400]	train's l1: 0.495023	valid's l1: 0.685698
[450]	train's l1: 0.493882	valid's l1: 0.68549
[500]	train's l1: 0.492666	valid's l1: 0.685241
[550]	train's l1: 0.491969	valid's l1: 0.685076
[600]	train's l1: 0.491196	valid's l1: 0.68512
Early stopping, best iteration is:
[573]	train's l1: 0.491628	valid's l1: 0.685045
  Fold 4: best_iteration = 573
Training until validation scores don't improve for 50 rounds
[50]	train's l1: 0.618762	valid's l1: 0.642222
[100]	train's l1: 0.547157	valid's l1: 0.636143
Early stopping, best iteration is:
[73]	train's l1: 0.569635	valid's l1: 0.63456
  Fold 5: best_iteration = 73
  Average best iterations: 218
Training 5-model ensemble with 218 iterations...
LightGBM_Ensemble         MAE: 9.8877, RMSE: 19.9947

======================================================================
CREATING VISUALIZATION
======================================================================
Visualization saved: results/final_model_comparison_best.png

======================================================================
FINAL SUMMARY
======================================================================

Model                     MAE (days)      RMSE (days)     RÂ²          
----------------------------------------------------------------------
RF_Conservative           9.7249          19.8887         0.004772    
LightGBM_Ensemble         9.8877          19.9947         -0.005861   
XGB_Conservative          9.9689          20.1048         -0.016968   
Baseline_1_SR_TYPE        12.0369         20.3727         -0.044253   
Baseline_3_SR_ZIP         13.4766         21.1897         -0.129693   
Baseline_0_Global         14.1621         20.2196         -0.028621   
Baseline_2_ZIP            14.1842         20.2262         -0.029288   
----------------------------------------------------------------------

Best Model: RF_Conservative
  MAE: 9.7249 days
  RMSE: 19.8887 days
  Improvement over best baseline: 19.2%

======================================================================

Results saved to results/model_results.csv
All done!

