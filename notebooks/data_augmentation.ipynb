{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather data augmentation - Chicago 311 Response Time Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell only if libraries are not installed\n",
    "# !pip install pandas numpy scikit-learn requests holidays geopy matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import holidays\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.model_selection import KFold\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"✓ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Base Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: ../data/raw/311_Service_Requests_Since_2020.csv\n",
      "File exists: True\n",
      "\n",
      "✓ Loaded 2,229,793 rows\n",
      "✓ Columns: 28\n",
      "\n",
      "Column names:\n",
      "['SR_NUMBER', 'SR_TYPE', 'SR_SHORT_CODE', 'ORIGIN', 'CREATED_DATE', 'CLOSED_DATE', 'ZIP_CODE', 'COMMUNITY_AREA', 'WARD', 'CREATED_HOUR', 'CREATED_DAY_OF_WEEK', 'CREATED_MONTH', 'X_COORDINATE', 'Y_COORDINATE', 'LATITUDE', 'LONGITUDE', 'CREATED_DEPARTMENT', 'OWNER_DEPARTMENT', 'ELECTRICAL_DISTRICT', 'ELECTRICITY_GRID', 'POLICE_SECTOR', 'POLICE_DISTRICT', 'POLICE_BEAT', 'PRECINCT', 'STREET_NUMBER', 'STREET_DIRECTION', 'STREET_NAME', 'STREET_TYPE']\n"
     ]
    }
   ],
   "source": [
    "# Load raw data from git-lfs\n",
    "data_path = Path('../data/raw/311_Service_Requests_Since_2020.csv')\n",
    "\n",
    "print(f\"Loading data from: {data_path}\")\n",
    "print(f\"File exists: {data_path.exists()}\")\n",
    "\n",
    "# Read CSV\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"\\n✓ Loaded {len(df):,} rows\")\n",
    "print(f\"✓ Columns: {df.shape[1]}\")\n",
    "print(f\"\\nColumn names:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SR_NUMBER</th>\n",
       "      <th>SR_TYPE</th>\n",
       "      <th>SR_SHORT_CODE</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>CREATED_DATE</th>\n",
       "      <th>CLOSED_DATE</th>\n",
       "      <th>ZIP_CODE</th>\n",
       "      <th>COMMUNITY_AREA</th>\n",
       "      <th>WARD</th>\n",
       "      <th>CREATED_HOUR</th>\n",
       "      <th>CREATED_DAY_OF_WEEK</th>\n",
       "      <th>CREATED_MONTH</th>\n",
       "      <th>X_COORDINATE</th>\n",
       "      <th>Y_COORDINATE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>CREATED_DEPARTMENT</th>\n",
       "      <th>OWNER_DEPARTMENT</th>\n",
       "      <th>ELECTRICAL_DISTRICT</th>\n",
       "      <th>ELECTRICITY_GRID</th>\n",
       "      <th>POLICE_SECTOR</th>\n",
       "      <th>POLICE_DISTRICT</th>\n",
       "      <th>POLICE_BEAT</th>\n",
       "      <th>PRECINCT</th>\n",
       "      <th>STREET_NUMBER</th>\n",
       "      <th>STREET_DIRECTION</th>\n",
       "      <th>STREET_NAME</th>\n",
       "      <th>STREET_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SR20-03236940</td>\n",
       "      <td>Graffiti Removal Request</td>\n",
       "      <td>GRAF</td>\n",
       "      <td>Mobile Device</td>\n",
       "      <td>01/01/2020 12:17:00 AM</td>\n",
       "      <td>01/02/2020 09:06:28 AM</td>\n",
       "      <td>60616.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.174071e+06</td>\n",
       "      <td>1.889129e+06</td>\n",
       "      <td>41.851184</td>\n",
       "      <td>-87.636608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Streets and Sanitation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>914.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2263</td>\n",
       "      <td>S</td>\n",
       "      <td>STEWART</td>\n",
       "      <td>AVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SR20-03236942</td>\n",
       "      <td>Rodent Baiting/Rat Complaint</td>\n",
       "      <td>SGA</td>\n",
       "      <td>Mobile Device</td>\n",
       "      <td>01/01/2020 12:19:30 AM</td>\n",
       "      <td>01/02/2020 10:12:43 AM</td>\n",
       "      <td>60632.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.148548e+06</td>\n",
       "      <td>1.871197e+06</td>\n",
       "      <td>41.802506</td>\n",
       "      <td>-87.730747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Streets and Sanitation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>815.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4955</td>\n",
       "      <td>S</td>\n",
       "      <td>KILDARE</td>\n",
       "      <td>AVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SR20-03236943</td>\n",
       "      <td>Garbage Cart Maintenance</td>\n",
       "      <td>SIE</td>\n",
       "      <td>Internet</td>\n",
       "      <td>01/01/2020 12:19:48 AM</td>\n",
       "      <td>02/20/2020 09:26:26 AM</td>\n",
       "      <td>60645.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.159299e+06</td>\n",
       "      <td>1.949262e+06</td>\n",
       "      <td>42.016509</td>\n",
       "      <td>-87.689169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Streets and Sanitation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2411.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7428</td>\n",
       "      <td>N</td>\n",
       "      <td>CLAREMONT</td>\n",
       "      <td>AVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SR20-03236974</td>\n",
       "      <td>Abandoned Vehicle Complaint</td>\n",
       "      <td>SKA</td>\n",
       "      <td>Internet</td>\n",
       "      <td>01/01/2020 12:43:32 AM</td>\n",
       "      <td>02/07/2020 02:18:57 PM</td>\n",
       "      <td>60656.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.128611e+06</td>\n",
       "      <td>1.935354e+06</td>\n",
       "      <td>41.978924</td>\n",
       "      <td>-87.802411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Streets and Sanitation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y109</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1613.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>5360</td>\n",
       "      <td>N</td>\n",
       "      <td>NORDICA</td>\n",
       "      <td>AVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SR20-03236988</td>\n",
       "      <td>Traffic Signal Out Complaint</td>\n",
       "      <td>SFB</td>\n",
       "      <td>Mobile Device</td>\n",
       "      <td>01/01/2020 12:55:40 AM</td>\n",
       "      <td>01/03/2020 09:51:41 AM</td>\n",
       "      <td>60622.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.164375e+06</td>\n",
       "      <td>1.913327e+06</td>\n",
       "      <td>41.917796</td>\n",
       "      <td>-87.671512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CDOT - Department of Transportation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L018</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1433.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1959</td>\n",
       "      <td>N</td>\n",
       "      <td>HERMITAGE</td>\n",
       "      <td>AVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SR_NUMBER                       SR_TYPE SR_SHORT_CODE         ORIGIN  \\\n",
       "0  SR20-03236940      Graffiti Removal Request          GRAF  Mobile Device   \n",
       "1  SR20-03236942  Rodent Baiting/Rat Complaint           SGA  Mobile Device   \n",
       "2  SR20-03236943      Garbage Cart Maintenance           SIE       Internet   \n",
       "3  SR20-03236974   Abandoned Vehicle Complaint           SKA       Internet   \n",
       "4  SR20-03236988  Traffic Signal Out Complaint           SFB  Mobile Device   \n",
       "\n",
       "             CREATED_DATE             CLOSED_DATE  ZIP_CODE  COMMUNITY_AREA  \\\n",
       "0  01/01/2020 12:17:00 AM  01/02/2020 09:06:28 AM   60616.0            34.0   \n",
       "1  01/01/2020 12:19:30 AM  01/02/2020 10:12:43 AM   60632.0            57.0   \n",
       "2  01/01/2020 12:19:48 AM  02/20/2020 09:26:26 AM   60645.0             2.0   \n",
       "3  01/01/2020 12:43:32 AM  02/07/2020 02:18:57 PM   60656.0            10.0   \n",
       "4  01/01/2020 12:55:40 AM  01/03/2020 09:51:41 AM   60622.0            22.0   \n",
       "\n",
       "   WARD  CREATED_HOUR  CREATED_DAY_OF_WEEK  CREATED_MONTH  X_COORDINATE  \\\n",
       "0  25.0             0                    4              1  1.174071e+06   \n",
       "1  14.0             0                    4              1  1.148548e+06   \n",
       "2  50.0             0                    4              1  1.159299e+06   \n",
       "3  41.0             0                    4              1  1.128611e+06   \n",
       "4  32.0             0                    4              1  1.164375e+06   \n",
       "\n",
       "   Y_COORDINATE   LATITUDE  LONGITUDE CREATED_DEPARTMENT  \\\n",
       "0  1.889129e+06  41.851184 -87.636608                NaN   \n",
       "1  1.871197e+06  41.802506 -87.730747                NaN   \n",
       "2  1.949262e+06  42.016509 -87.689169                NaN   \n",
       "3  1.935354e+06  41.978924 -87.802411                NaN   \n",
       "4  1.913327e+06  41.917796 -87.671512                NaN   \n",
       "\n",
       "                      OWNER_DEPARTMENT  ELECTRICAL_DISTRICT ELECTRICITY_GRID  \\\n",
       "0               Streets and Sanitation                  NaN             P027   \n",
       "1               Streets and Sanitation                  NaN             F033   \n",
       "2               Streets and Sanitation                  NaN             K004   \n",
       "3               Streets and Sanitation                  NaN             Y109   \n",
       "4  CDOT - Department of Transportation                  NaN             L018   \n",
       "\n",
       "   POLICE_SECTOR  POLICE_DISTRICT  POLICE_BEAT  PRECINCT STREET_NUMBER  \\\n",
       "0            1.0              9.0        914.0      18.0          2263   \n",
       "1            1.0              8.0        815.0       8.0          4955   \n",
       "2            1.0             24.0       2411.0       8.0          7428   \n",
       "3            1.0             16.0       1613.0      45.0          5360   \n",
       "4            3.0             14.0       1433.0      33.0          1959   \n",
       "\n",
       "  STREET_DIRECTION STREET_NAME STREET_TYPE  \n",
       "0                S     STEWART         AVE  \n",
       "1                S     KILDARE         AVE  \n",
       "2                N   CLAREMONT         AVE  \n",
       "3                N     NORDICA         AVE  \n",
       "4                N   HERMITAGE         AVE  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2229793 entries, 0 to 2229792\n",
      "Data columns (total 28 columns):\n",
      " #   Column               Dtype  \n",
      "---  ------               -----  \n",
      " 0   SR_NUMBER            object \n",
      " 1   SR_TYPE              object \n",
      " 2   SR_SHORT_CODE        object \n",
      " 3   ORIGIN               object \n",
      " 4   CREATED_DATE         object \n",
      " 5   CLOSED_DATE          object \n",
      " 6   ZIP_CODE             float64\n",
      " 7   COMMUNITY_AREA       float64\n",
      " 8   WARD                 float64\n",
      " 9   CREATED_HOUR         int64  \n",
      " 10  CREATED_DAY_OF_WEEK  int64  \n",
      " 11  CREATED_MONTH        int64  \n",
      " 12  X_COORDINATE         float64\n",
      " 13  Y_COORDINATE         float64\n",
      " 14  LATITUDE             float64\n",
      " 15  LONGITUDE            float64\n",
      " 16  CREATED_DEPARTMENT   object \n",
      " 17  OWNER_DEPARTMENT     object \n",
      " 18  ELECTRICAL_DISTRICT  float64\n",
      " 19  ELECTRICITY_GRID     object \n",
      " 20  POLICE_SECTOR        float64\n",
      " 21  POLICE_DISTRICT      float64\n",
      " 22  POLICE_BEAT          float64\n",
      " 23  PRECINCT             float64\n",
      " 24  STREET_NUMBER        object \n",
      " 25  STREET_DIRECTION     object \n",
      " 26  STREET_NAME          object \n",
      " 27  STREET_TYPE          object \n",
      "dtypes: float64(12), int64(3), object(13)\n",
      "memory usage: 476.3+ MB\n",
      "\n",
      "Missing values:\n",
      "SR_NUMBER                    0\n",
      "SR_TYPE                      0\n",
      "SR_SHORT_CODE                0\n",
      "ORIGIN                       0\n",
      "CREATED_DATE                 0\n",
      "CLOSED_DATE              29833\n",
      "ZIP_CODE                388137\n",
      "COMMUNITY_AREA            6320\n",
      "WARD                      6047\n",
      "CREATED_HOUR                 0\n",
      "CREATED_DAY_OF_WEEK          0\n",
      "CREATED_MONTH                0\n",
      "X_COORDINATE              4132\n",
      "Y_COORDINATE              4132\n",
      "LATITUDE                  4148\n",
      "LONGITUDE                 4148\n",
      "CREATED_DEPARTMENT     1207817\n",
      "OWNER_DEPARTMENT             0\n",
      "ELECTRICAL_DISTRICT    1935090\n",
      "ELECTRICITY_GRID          7550\n",
      "POLICE_SECTOR             5913\n",
      "POLICE_DISTRICT           5913\n",
      "POLICE_BEAT               5913\n",
      "PRECINCT                  7226\n",
      "STREET_NUMBER             4600\n",
      "STREET_DIRECTION          4733\n",
      "STREET_NAME               4414\n",
      "STREET_TYPE              46373\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check data types and missing values\n",
    "print(\"Data Info:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting date columns...\n",
      "Sample CREATED_DATE: 01/01/2020 12:17:00 AM\n",
      "Sample CLOSED_DATE: 01/02/2020 09:06:28 AM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jv/2mp5gk6d2c54cp2653crmxw80000gn/T/ipykernel_89180/16862326.py:9: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['CREATED_DATE'] = pd.to_datetime(df['CREATED_DATE'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Converted dates\n",
      "CREATED_DATE range: 2020-01-01 00:17:00 to 2025-09-30 20:13:05\n",
      "CLOSED_DATE range: 2020-01-01 09:28:15 to 2025-09-30 20:12:47\n"
     ]
    }
   ],
   "source": [
    "# Convert date columns to datetime\n",
    "print(\"Converting date columns...\")\n",
    "\n",
    "# Check the actual format of the dates\n",
    "print(f\"Sample CREATED_DATE: {df['CREATED_DATE'].iloc[0]}\")\n",
    "print(f\"Sample CLOSED_DATE: {df['CLOSED_DATE'].iloc[0] if pd.notna(df['CLOSED_DATE'].iloc[0]) else 'NaN'}\")\n",
    "\n",
    "# Convert to datetime (adjust format if needed based on sample)\n",
    "df['CREATED_DATE'] = pd.to_datetime(df['CREATED_DATE'], errors='coerce')\n",
    "df['CLOSED_DATE'] = pd.to_datetime(df['CLOSED_DATE'], errors='coerce')\n",
    "\n",
    "print(f\"\\n✓ Converted dates\")\n",
    "print(f\"CREATED_DATE range: {df['CREATED_DATE'].min()} to {df['CREATED_DATE'].max()}\")\n",
    "print(f\"CLOSED_DATE range: {df['CLOSED_DATE'].min()} to {df['CLOSED_DATE'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted base temporal features:\n",
      "  - CREATED_HOUR (0-23)\n",
      "  - CREATED_DAY_OF_WEEK (0-6, Monday-Sunday)\n",
      "  - CREATED_MONTH (1-12)\n",
      "  - CREATED_DATE_ONLY (for weather merge)\n",
      "\n",
      "Sample temporal features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CREATED_DATE</th>\n",
       "      <th>CREATED_HOUR</th>\n",
       "      <th>CREATED_DAY_OF_WEEK</th>\n",
       "      <th>CREATED_MONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 00:17:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01 00:19:30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01 00:19:48</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01 00:43:32</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01 00:55:40</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CREATED_DATE  CREATED_HOUR  CREATED_DAY_OF_WEEK  CREATED_MONTH\n",
       "0 2020-01-01 00:17:00             0                    2              1\n",
       "1 2020-01-01 00:19:30             0                    2              1\n",
       "2 2020-01-01 00:19:48             0                    2              1\n",
       "3 2020-01-01 00:43:32             0                    2              1\n",
       "4 2020-01-01 00:55:40             0                    2              1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract base temporal features\n",
    "df['CREATED_HOUR'] = df['CREATED_DATE'].dt.hour\n",
    "df['CREATED_DAY_OF_WEEK'] = df['CREATED_DATE'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "df['CREATED_MONTH'] = df['CREATED_DATE'].dt.month\n",
    "df['CREATED_DATE_ONLY'] = df['CREATED_DATE'].dt.date\n",
    "\n",
    "print(\"✓ Extracted base temporal features:\")\n",
    "print(f\"  - CREATED_HOUR (0-23)\")\n",
    "print(f\"  - CREATED_DAY_OF_WEEK (0-6, Monday-Sunday)\")\n",
    "print(f\"  - CREATED_MONTH (1-12)\")\n",
    "print(f\"  - CREATED_DATE_ONLY (for weather merge)\")\n",
    "\n",
    "print(f\"\\nSample temporal features:\")\n",
    "df[['CREATED_DATE', 'CREATED_HOUR', 'CREATED_DAY_OF_WEEK', 'CREATED_MONTH']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather Data Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data date range: 2020-01-01 to 2025-09-30\n",
      "Total days needed: 2100\n",
      "Fetching weather data from Open-Meteo API (2020-01-01 to 2025-09-30)...\n",
      "✓ Fetched 2100 days of weather data\n",
      "✓ Cached to ../data/raw/chicago_weather_full.csv\n",
      "\n",
      "Weather data preview:\n",
      "        date  temp_mean  precipitation  snowfall\n",
      "0 2020-01-01       31.1          0.000     0.000\n",
      "1 2020-01-02       40.8          0.000     0.000\n",
      "2 2020-01-03       34.6          0.000     0.000\n",
      "3 2020-01-04       30.6          0.079     0.551\n",
      "4 2020-01-05       31.7          0.004     0.028\n",
      "5 2020-01-06       31.7          0.000     0.000\n",
      "6 2020-01-07       32.4          0.008     0.055\n",
      "7 2020-01-08       20.8          0.000     0.000\n",
      "8 2020-01-09       38.6          0.012     0.000\n",
      "9 2020-01-10       41.0          0.748     0.000\n",
      "\n",
      "Weather statistics:\n",
      "                                date    temp_mean  precipitation     snowfall\n",
      "count                           2100  2100.000000    2100.000000  2100.000000\n",
      "mean   2022-11-15 12:00:00.000000256    51.282143       0.117149     0.070805\n",
      "min              2020-01-01 00:00:00    -7.000000       0.000000     0.000000\n",
      "25%              2021-06-08 18:00:00    36.075000       0.000000     0.000000\n",
      "50%              2022-11-15 12:00:00    52.000000       0.004000     0.000000\n",
      "75%              2024-04-23 06:00:00    68.500000       0.098000     0.000000\n",
      "max              2025-09-30 00:00:00    86.900000       5.425000     4.520000\n",
      "std                              NaN    18.815777       0.280855     0.343135\n"
     ]
    }
   ],
   "source": [
    "def fetch_chicago_weather(start_date, end_date, cache_path):\n",
    "    \"\"\"\n",
    "    Fetch historical weather data for Chicago from Open-Meteo API.\n",
    "\n",
    "    Args:\n",
    "        start_date: Start date (YYYY-MM-DD)\n",
    "        end_date: End date (YYYY-MM-DD)\n",
    "        cache_path: Path to cache the weather data\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Daily weather data\n",
    "    \"\"\"\n",
    "    # Check if cache exists\n",
    "    if Path(cache_path).exists():\n",
    "        print(f\"Loading cached weather data from {cache_path}...\")\n",
    "        weather_df = pd.read_csv(cache_path, parse_dates=['date'])\n",
    "        print(f\"✓ Loaded {len(weather_df)} days from cache\")\n",
    "        return weather_df\n",
    "\n",
    "    print(f\"Fetching weather data from Open-Meteo API ({start_date} to {end_date})...\")\n",
    "\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "    # Only fetch features that matter for prediction:\n",
    "    # - Temperature (work speed, equipment function)\n",
    "    # - Precipitation (delays outdoor work)\n",
    "    # - Snow (road access, delays)\n",
    "    params = {\n",
    "        \"latitude\": 41.8781,  # Chicago Loop\n",
    "        \"longitude\": -87.6298,\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"daily\": [\n",
    "            \"temperature_2m_mean\",      # Daily mean temp\n",
    "            \"precipitation_sum\",         # Total precipitation\n",
    "            \"snowfall_sum\",             # Total snowfall\n",
    "        ],\n",
    "        \"temperature_unit\": \"fahrenheit\",\n",
    "        \"precipitation_unit\": \"inch\",\n",
    "        \"timezone\": \"America/Chicago\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Weather API error: {response.status_code}\\n{response.text}\")\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "    # Convert to DataFrame - only keep essential features\n",
    "    weather_df = pd.DataFrame({\n",
    "        'date': pd.to_datetime(data['daily']['time']),\n",
    "        'temp_mean': data['daily']['temperature_2m_mean'],\n",
    "        'precipitation': data['daily']['precipitation_sum'],\n",
    "        'snowfall': data['daily']['snowfall_sum'],\n",
    "    })\n",
    "\n",
    "    # Cache the results\n",
    "    weather_df.to_csv(cache_path, index=False)\n",
    "    print(f\"✓ Fetched {len(weather_df)} days of weather data\")\n",
    "    print(f\"✓ Cached to {cache_path}\")\n",
    "\n",
    "    return weather_df\n",
    "\n",
    "# Determine date range from our data\n",
    "min_date = df['CREATED_DATE'].min().date()\n",
    "max_date = df['CREATED_DATE'].max().date()\n",
    "\n",
    "print(f\"Data date range: {min_date} to {max_date}\")\n",
    "print(f\"Total days needed: {(max_date - min_date).days + 1}\")\n",
    "\n",
    "# Fetch weather for full date range\n",
    "cache_path = Path('../data/raw/chicago_weather_full.csv')\n",
    "weather_df = fetch_chicago_weather(\n",
    "    start_date=str(min_date),\n",
    "    end_date=str(max_date),\n",
    "    cache_path=cache_path\n",
    ")\n",
    "\n",
    "print(\"\\nWeather data preview:\")\n",
    "print(weather_df.head(10))\n",
    "print(\"\\nWeather statistics:\")\n",
    "print(weather_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging weather data...\n",
      "  Main dataset rows before merge: 2,229,793\n",
      "  Weather data dates: 2,100\n",
      "  Main dataset rows after merge: 2,229,793\n",
      "  Rows with missing weather: 0 (0.00%)\n",
      "\n",
      "✓ Weather data merged successfully\n"
     ]
    }
   ],
   "source": [
    "# Prepare weather data for merge (date only, no time)\n",
    "weather_df['date'] = pd.to_datetime(weather_df['date']).dt.date\n",
    "\n",
    "# Merge weather data to main dataset\n",
    "print(f\"Merging weather data...\")\n",
    "print(f\"  Main dataset rows before merge: {len(df):,}\")\n",
    "print(f\"  Weather data dates: {len(weather_df):,}\")\n",
    "\n",
    "df = df.merge(weather_df, left_on='CREATED_DATE_ONLY', right_on='date', how='left')\n",
    "\n",
    "print(f\"  Main dataset rows after merge: {len(df):,}\")\n",
    "\n",
    "# Check for missing weather data\n",
    "missing_weather = df['temp_mean'].isna().sum()\n",
    "print(f\"  Rows with missing weather: {missing_weather:,} ({missing_weather/len(df)*100:.2f}%)\")\n",
    "\n",
    "if missing_weather > 0:\n",
    "    # Show which dates are missing\n",
    "    missing_dates = df[df['temp_mean'].isna()]['CREATED_DATE_ONLY'].unique()\n",
    "    print(f\"  Missing dates sample: {sorted(missing_dates)[:5]}\")\n",
    "\n",
    "print(\"\\n✓ Weather data merged successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating derived weather features...\n",
      "\n",
      "✓ extreme_cold: 69,533 requests on extreme cold days\n",
      "✓ heavy_precipitation: 158,404 requests on heavy rain days\n",
      "✓ snow_day: 200,641 requests on snow days\n",
      "✓ temp_deviation calculated\n",
      "  Range: -35.9°F to 27.9°F\n",
      "\n",
      "✓ Created 4 derived weather features (simplified)\n"
     ]
    }
   ],
   "source": [
    "# Create simplified derived weather features (only predictive ones)\n",
    "print(\"Creating derived weather features...\\n\")\n",
    "\n",
    "# 1. Extreme cold (below 20°F mean) - impacts work speed and equipment\n",
    "df['extreme_cold'] = (df['temp_mean'] < 20).fillna(0).astype(int)\n",
    "extreme_cold_count = (df['temp_mean'] < 20).sum()\n",
    "print(f\"✓ extreme_cold: {extreme_cold_count:,} requests on extreme cold days\")\n",
    "\n",
    "# 2. Heavy precipitation (>0.5 inches) - delays outdoor work\n",
    "df['heavy_precipitation'] = (df['precipitation'] > 0.5).fillna(0).astype(int)\n",
    "heavy_precip_count = (df['precipitation'] > 0.5).sum()\n",
    "print(f\"✓ heavy_precipitation: {heavy_precip_count:,} requests on heavy rain days\")\n",
    "\n",
    "# 3. Snow day (any measurable snowfall) - affects road access and work\n",
    "df['snow_day'] = (df['snowfall'] > 0).fillna(0).astype(int)\n",
    "snow_day_count = (df['snowfall'] > 0).sum()\n",
    "print(f\"✓ snow_day: {snow_day_count:,} requests on snow days\")\n",
    "\n",
    "# 4. Temperature deviation from monthly normal - unusual weather disrupts operations\n",
    "# Chicago average temps by month (historical normals)\n",
    "monthly_normal_temps = {\n",
    "    1: 27, 2: 30, 3: 41, 4: 52, 5: 63, 6: 72,\n",
    "    7: 77, 8: 75, 9: 68, 10: 56, 11: 43, 12: 31\n",
    "}\n",
    "df['temp_normal'] = df['CREATED_MONTH'].map(monthly_normal_temps)\n",
    "df['temp_deviation'] = (df['temp_mean'] - df['temp_normal']).fillna(0)\n",
    "\n",
    "print(f\"✓ temp_deviation calculated\")\n",
    "print(f\"  Range: {df['temp_deviation'].min():.1f}°F to {df['temp_deviation'].max():.1f}°F\")\n",
    "\n",
    "print(\"\\n✓ Created 4 derived weather features (simplified)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "WEATHER DATA AUGMENTATION COMPLETE (FIXED)\n",
      "============================================================\n",
      "\n",
      "Total weather features added: 7\n",
      "\n",
      "Feature list (simplified for prediction):\n",
      "  1. temp_mean\n",
      "  2. precipitation\n",
      "  3. snowfall\n",
      "  4. extreme_cold\n",
      "  5. heavy_precipitation\n",
      "  6. snow_day\n",
      "  7. temp_deviation\n",
      "\n",
      "Current dataset shape: (2229793, 38)\n",
      "Total rows: 2,229,793\n",
      "\n",
      "Missing weather data: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "# Summary of all weather features\n",
    "weather_features = [\n",
    "    # Base weather metrics (3)\n",
    "    'temp_mean',\n",
    "    'precipitation',\n",
    "    'snowfall',\n",
    "    # Derived features (4)\n",
    "    'extreme_cold',\n",
    "    'heavy_precipitation',\n",
    "    'snow_day',\n",
    "    'temp_deviation'\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"WEATHER DATA AUGMENTATION COMPLETE (FIXED)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal weather features added: {len(weather_features)}\")\n",
    "print(\"\\nFeature list (simplified for prediction):\")\n",
    "for i, feat in enumerate(weather_features, 1):\n",
    "    print(f\"  {i}. {feat}\")\n",
    "\n",
    "print(f\"\\nCurrent dataset shape: {df.shape}\")\n",
    "print(f\"Total rows: {len(df):,}\")\n",
    "print(f\"\\nMissing weather data: {df['temp_mean'].isna().sum():,} ({df['temp_mean'].isna().sum()/len(df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Weather Merge Quality\n",
    "\n",
    "Let's check the quality of the merge and see if weather data is properly aligned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather Data Merge Quality Check:\n",
      "\n",
      "Records with weather data: 2,229,793 (100.00%)\n",
      "Records missing weather:   0 (0.00%)\n",
      "\n",
      "Records by year:\n",
      "               total  with_weather  pct_with_weather\n",
      "CREATED_DATE                                        \n",
      "2020          427258        427258             100.0\n",
      "2021          390988        390988             100.0\n",
      "2022          367845        367845             100.0\n",
      "2023          359983        359983             100.0\n",
      "2024          389203        389203             100.0\n",
      "2025          294516        294516             100.0\n",
      "\n",
      "Sample of merged data (with weather):\n",
      "         CREATED_DATE  temp_mean  precipitation  snowfall  extreme_cold  \\\n",
      "0 2020-01-01 00:17:00       31.1            0.0       0.0             0   \n",
      "1 2020-01-01 00:19:30       31.1            0.0       0.0             0   \n",
      "2 2020-01-01 00:19:48       31.1            0.0       0.0             0   \n",
      "3 2020-01-01 00:43:32       31.1            0.0       0.0             0   \n",
      "4 2020-01-01 00:55:40       31.1            0.0       0.0             0   \n",
      "5 2020-01-01 00:56:03       31.1            0.0       0.0             0   \n",
      "6 2020-01-01 01:52:05       31.1            0.0       0.0             0   \n",
      "7 2020-01-01 02:18:47       31.1            0.0       0.0             0   \n",
      "8 2020-01-01 03:21:36       31.1            0.0       0.0             0   \n",
      "9 2020-01-01 03:23:06       31.1            0.0       0.0             0   \n",
      "\n",
      "   snow_day  \n",
      "0         0  \n",
      "1         0  \n",
      "2         0  \n",
      "3         0  \n",
      "4         0  \n",
      "5         0  \n",
      "6         0  \n",
      "7         0  \n",
      "8         0  \n",
      "9         0  \n"
     ]
    }
   ],
   "source": [
    "# Check merge quality\n",
    "print(\"Weather Data Merge Quality Check:\\n\")\n",
    "\n",
    "# Count records with weather data\n",
    "has_weather = df['temp_mean'].notna().sum()\n",
    "missing_weather = df['temp_mean'].isna().sum()\n",
    "\n",
    "print(f\"Records with weather data: {has_weather:,} ({has_weather/len(df)*100:.2f}%)\")\n",
    "print(f\"Records missing weather:   {missing_weather:,} ({missing_weather/len(df)*100:.2f}%)\")\n",
    "\n",
    "# Check distribution across years\n",
    "print(\"\\nRecords by year:\")\n",
    "year_stats = df.groupby(df['CREATED_DATE'].dt.year).agg({\n",
    "    'SR_NUMBER': 'count',\n",
    "    'temp_mean': lambda x: x.notna().sum()\n",
    "}).rename(columns={'SR_NUMBER': 'total', 'temp_mean': 'with_weather'})\n",
    "year_stats['pct_with_weather'] = (year_stats['with_weather'] / year_stats['total'] * 100).round(2)\n",
    "print(year_stats)\n",
    "\n",
    "# Sample of data with weather\n",
    "print(\"\\nSample of merged data (with weather):\")\n",
    "print(df[df['temp_mean'].notna()][['CREATED_DATE', 'temp_mean', 'precipitation', 'snowfall', 'extreme_cold', 'snow_day']].head(10))\n",
    "\n",
    "# If missing data, show which dates\n",
    "if missing_weather > 0:\n",
    "    print(f\"\\nDates with missing weather (sample):\")\n",
    "    missing_dates = sorted(df[df['temp_mean'].isna()]['CREATED_DATE_ONLY'].unique())\n",
    "    print(f\"  First 10: {missing_dates[:10]}\")\n",
    "    print(f\"  Last 10: {missing_dates[-10:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather Feature Statistics (non-null values only):\n",
      "\n",
      "temp_mean:\n",
      "  Count: 2,229,793\n",
      "  Mean: 54.38\n",
      "  Min: -7.00\n",
      "  Max: 86.90\n",
      "\n",
      "precipitation:\n",
      "  Count: 2,229,793\n",
      "  Mean: 0.12\n",
      "  Min: 0.00\n",
      "  Max: 5.42\n",
      "\n",
      "snowfall:\n",
      "  Count: 2,229,793\n",
      "  Mean: 0.05\n",
      "  Min: 0.00\n",
      "  Max: 4.52\n",
      "\n",
      "extreme_cold:\n",
      "  Count: 2,229,793\n",
      "  Mean: 0.03\n",
      "  Min: 0.00\n",
      "  Max: 1.00\n",
      "\n",
      "heavy_precipitation:\n",
      "  Count: 2,229,793\n",
      "  Mean: 0.07\n",
      "  Min: 0.00\n",
      "  Max: 1.00\n",
      "\n",
      "snow_day:\n",
      "  Count: 2,229,793\n",
      "  Mean: 0.09\n",
      "  Min: 0.00\n",
      "  Max: 1.00\n",
      "\n",
      "temp_deviation:\n",
      "  Count: 2,229,793\n",
      "  Mean: -1.84\n",
      "  Min: -35.90\n",
      "  Max: 27.90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Weather feature statistics\n",
    "print(\"Weather Feature Statistics (non-null values only):\\n\")\n",
    "\n",
    "weather_cols = ['temp_mean', 'precipitation', 'snowfall', 'extreme_cold', 'heavy_precipitation', 'snow_day', 'temp_deviation']\n",
    "\n",
    "for col in weather_cols:\n",
    "    if col in df.columns:\n",
    "        non_null = df[col].notna().sum()\n",
    "        print(f\"{col}:\")\n",
    "        if df[col].dtype in ['int64', 'float64']:\n",
    "            print(f\"  Count: {non_null:,}\")\n",
    "            print(f\"  Mean: {df[col].mean():.2f}\")\n",
    "            print(f\"  Min: {df[col].min():.2f}\")\n",
    "            print(f\"  Max: {df[col].max():.2f}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Progress: Weather-Augmented Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved weather-augmented dataset to ../data/processed/311_Service_Requests_Since_2020_with_weather.csv\n",
      "  Rows: 2,229,793\n",
      "  Columns: 38\n",
      "  Weather features: 7\n"
     ]
    }
   ],
   "source": [
    "# Save intermediate result with weather features\n",
    "output_dir = Path('../data/processed')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "output_path = output_dir / '311_Service_Requests_Since_2020_with_weather.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✓ Saved weather-augmented dataset to {output_path}\")\n",
    "print(f\"  Rows: {len(df):,}\")\n",
    "print(f\"  Columns: {df.shape[1]}\")\n",
    "print(f\"  Weather features: {len(weather_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weather Features Added:**\n",
    "- **Base metrics (3):** temp_mean, precipitation, snowfall\n",
    "- **Derived flags (4):** extreme_cold, heavy_precipitation, snow_day, temp_deviation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
